{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06c0d564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2232f097510>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from scipy.spatial import distance\n",
    "from tqdm import tqdm\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.datasets import data, utils, configs\n",
    "from src.datasets.utils import dump_generated_dataset, PreGeneratedDataset\n",
    "from src.metrics import hungarian_slots_loss\n",
    "from src.utils.training_utils import sample_z_from_latents\n",
    "\n",
    "\n",
    "from torchvision import transforms as transforms\n",
    "\n",
    "import imageio\n",
    "\n",
    "seed = 43\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9554c463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_objects(latents, max_objects=5000, threshold=0.3, sort=False):\n",
    "    \"\"\"\n",
    "    Filter objects based on their Euclidean distance.\n",
    "    Args:\n",
    "        latents: Tensor of shape (batch_size, n_slots, n_latents)\n",
    "        max_objects: Number of objects to keep at most\n",
    "        threshold: Distance threshold\n",
    "        sort: Whether to sort the objects by distance\n",
    "    \"\"\"\n",
    "    N, slots, _ = latents.size()\n",
    "    mask = torch.zeros(N, dtype=bool)\n",
    "\n",
    "    # Compute Euclidean distance for each pair of slots in each item\n",
    "    for n in range(N):\n",
    "        slots_distances = torch.cdist(latents[n, :, :2], latents[n, :, :2], p=2)\n",
    "        slots_distances.fill_diagonal_(float('inf'))  # Ignore distance to self\n",
    "\n",
    "        # Consider an object as \"close\" if its minimal distance to any other object is below the threshold\n",
    "        min_distance = slots_distances.min().item()\n",
    "        if min_distance >= threshold:\n",
    "            mask[n] = True\n",
    "\n",
    "    # If all objects are \"close\", print a message and return\n",
    "    if not torch.any(mask):\n",
    "        print(\"No objects were found that meet the distance threshold.\")\n",
    "        return None, []\n",
    "\n",
    "    # Apply the mask to the latents\n",
    "    filtered_objects = latents[mask]\n",
    "    filtered_indices = torch.arange(N)[mask]\n",
    "\n",
    "    # If the number of filtered objects exceeds the maximum, truncate them\n",
    "    if filtered_objects.size(0) > max_objects:\n",
    "        filtered_objects = filtered_objects[:max_objects]\n",
    "        filtered_indices = filtered_indices[:max_objects]\n",
    "\n",
    "    if sort:\n",
    "        # Sort the filtered objects by minimum distance to any other object\n",
    "        min_distances = torch.zeros(mask.sum().item())\n",
    "        for i, n in enumerate(torch.where(mask)[0]):\n",
    "            slots_distances = torch.cdist(latents[n], latents[n], p=2)\n",
    "            slots_distances.fill_diagonal_(float('inf'))\n",
    "            min_distances[i] = slots_distances.min().item()\n",
    "\n",
    "        indices = torch.argsort(min_distances)\n",
    "        filtered_objects = filtered_objects[indices]\n",
    "        filtered_indices = filtered_indices[indices]\n",
    "\n",
    "    return filtered_objects, filtered_indices.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aba3c949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating images (sampling: off_diagonal): 100%|███████████████████████████████| 10000/10000 [01:25<00:00, 117.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create a diagonal dataset, to get valid latents\n",
    "n_samples = 10000\n",
    "n_slots = 2\n",
    "default_cfg = configs.SpriteWorldConfig()\n",
    "sample_mode = \"off_diagonal\"\n",
    "no_overlap = True\n",
    "delta = 0.125\n",
    "\n",
    "off_diagonal_dataset = data.SpriteWorldDataset(\n",
    "    n_samples,\n",
    "    n_slots,\n",
    "    default_cfg,\n",
    "    sample_mode=sample_mode,\n",
    "    no_overlap=no_overlap,\n",
    "    delta=delta,\n",
    "    transform=transforms.Compose(\n",
    "    [transforms.ToPILImage(), transforms.ToTensor()]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "938e1eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_data(index, dataset):\n",
    "    plt.imshow(dataset[index][0][-1].permute(1, 2, 0))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bfdbe01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d6382df4adc4b15bba539246fcceec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=9999), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dispaly_off_diagonal = lambda index: display_data(index, dataset=off_diagonal_dataset)\n",
    "\n",
    "num_samples = len(off_diagonal_dataset)\n",
    "\n",
    "# slider\n",
    "widgets.interact(dispaly_off_diagonal, index=widgets.IntSlider(min=0, max=num_samples-1, step=1, value=0));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2da8741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, indicies = filter_objects(off_diagonal_dataset.z, max_objects=5000, threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f62efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(off_diagonal_dataset.x[indicies], \"D:/mnt/qb/work/bethge/apanfilov27/object_centric_consistency_project/dsprites/test/new_ood/2_objects/images/images.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fcace7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.cat([off_diagonal_dataset.z[indicies, :, :4], off_diagonal_dataset.z[indicies, :, 5:-2]], dim=-1), \"D:/mnt/qb/work/bethge/apanfilov27/object_centric_consistency_project/dsprites/test/new_ood/2_objects/latents/latents.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c0d07dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_overlaps_ood = PreGeneratedDataset(\"D:/mnt/qb/work/bethge/apanfilov27/object_centric_consistency_project/dsprites/test/new_ood/2_objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90de7c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa63367cc764727ad32580fbf97dcb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=4999), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dispaly_no_overlaps_ood = lambda index: display_data(index, dataset=no_overlaps_ood)\n",
    "\n",
    "num_samples = len(no_overlaps_ood)\n",
    "\n",
    "# slider\n",
    "widgets.interact(dispaly_no_overlaps_ood, index=widgets.IntSlider(min=0, max=num_samples-1, step=1, value=0));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60783d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(diagonal_dataset.x, \"D:/mnt/qb/work/bethge/apanfilov27/object_centric_consistency_project/dsprites/test/random/mixed/images/images_2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02eca241",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.cat([diagonal_dataset.z[:, :, :4], diagonal_dataset.z[:, :, 5:-2]], dim=-1), \"D:/mnt/qb/work/bethge/apanfilov27/object_centric_consistency_project/dsprites/test/random/mixed/latents/latents_2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06202125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 2, 8])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c051060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(diagonal_dataset.z, \"D:/mnt/qb/heatmap_dataset/initial_id_latents.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4adc1d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta is too big for 'no_overlap' mode, setting it to 0.08333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating images (sampling: diagonal): 100%|██████████████████████████████████████| 2673/2673 [00:38<00:00, 68.78it/s]\n"
     ]
    }
   ],
   "source": [
    "diagonal_dataset = data.SpriteWorldDataset(\n",
    "    len(new_z),\n",
    "    n_slots,\n",
    "    default_cfg,\n",
    "    sample_mode=sample_mode,\n",
    "    no_overlap=no_overlap,\n",
    "    delta=delta,\n",
    "    transform=transforms.Compose(\n",
    "    [transforms.ToPILImage(), transforms.ToTensor()]),\n",
    "    z=new_z\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92ec3f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating images (sampling: off_diagonal): 100%|█████████████████████████████████| 5000/5000 [00:44<00:00, 111.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Create a off_diagonal dataset, to get valid latents\n",
    "n_samples = 5000\n",
    "n_slots = 2\n",
    "default_cfg = configs.SpriteWorldConfig()\n",
    "sample_mode = \"off_diagonal\"\n",
    "no_overlap = False\n",
    "delta = 0.125\n",
    "\n",
    "off_diagonal_dataset = data.SpriteWorldDataset(\n",
    "    n_samples,\n",
    "    n_slots,\n",
    "    default_cfg,\n",
    "    sample_mode=sample_mode,\n",
    "    no_overlap=no_overlap,\n",
    "    delta=delta,\n",
    "    transform=transforms.Compose(\n",
    "    [transforms.ToPILImage(), transforms.ToTensor()])\n",
    ")\n",
    "\n",
    "# Extract ood_latents and replace their x and y coordinate by diagonal latens\n",
    "no_overlap_z = off_diagonal_dataset.z.clone()\n",
    "no_overlap_z[:, :, :1] = diagonal_dataset.z[:, :, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2bbc8a61",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating images (sampling: off_diagonal):  50%|████████████████▌                | 2501/5000 [00:23<00:23, 106.27it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[33], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m no_overlap \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m      8\u001B[0m delta \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.125\u001B[39m\n\u001B[1;32m---> 10\u001B[0m no_overlap_off_diagonal_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSpriteWorldDataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_slots\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdefault_cfg\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43mno_overlap\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mno_overlap\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdelta\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransforms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCompose\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[43mtransforms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mToPILImage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransforms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mToTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43mz\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mno_overlap_z\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\git_projects\\bethgelab\\lab_rotation\\object_centric_ood\\notebooks\\..\\src\\datasets\\data.py:136\u001B[0m, in \u001B[0;36mSpriteWorldDataset.__init__\u001B[1;34m(self, n_samples, n_slots, cfg, sample_mode, img_h, img_w, delta, no_overlap, transform, z, **kwargs)\u001B[0m\n\u001B[0;32m    127\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__generate_ind \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    128\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menv \u001B[38;5;241m=\u001B[39m environment\u001B[38;5;241m.\u001B[39mEnvironment(\n\u001B[0;32m    129\u001B[0m     task\u001B[38;5;241m=\u001B[39mtasks\u001B[38;5;241m.\u001B[39mNoReward(),\n\u001B[0;32m    130\u001B[0m     action_space\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    133\u001B[0m     max_episode_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m    134\u001B[0m )\n\u001B[1;32m--> 136\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__generate_from_latents\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mdetach()\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__update_latents(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mz))\n",
      "File \u001B[1;32mD:\\git_projects\\bethgelab\\lab_rotation\\object_centric_ood\\notebooks\\..\\src\\datasets\\data.py:189\u001B[0m, in \u001B[0;36mSpriteWorldDataset.__generate_from_latents\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    184\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m sample_ind \u001B[38;5;129;01min\u001B[39;00m tqdm\u001B[38;5;241m.\u001B[39mtqdm(\n\u001B[0;32m    185\u001B[0m     \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_samples),\n\u001B[0;32m    186\u001B[0m     desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGenerating images (sampling: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msample_mode\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    187\u001B[0m ):\n\u001B[0;32m    188\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__generate_ind \u001B[38;5;241m=\u001B[39m sample_ind\n\u001B[1;32m--> 189\u001B[0m     ts \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreset\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    190\u001B[0m     out \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(np\u001B[38;5;241m.\u001B[39marray(ts\u001B[38;5;241m.\u001B[39mobservation[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m\"\u001B[39m]))\n\u001B[0;32m    192\u001B[0m     images[sample_ind] \u001B[38;5;241m=\u001B[39m out\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n",
      "File \u001B[1;32mC:\\Python310\\lib\\site-packages\\spriteworld\\environment.py:78\u001B[0m, in \u001B[0;36mEnvironment.reset\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     76\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_step_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset_next_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m---> 78\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m dm_env\u001B[38;5;241m.\u001B[39mrestart(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobservation\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32mC:\\Python310\\lib\\site-packages\\spriteworld\\environment.py:138\u001B[0m, in \u001B[0;36mEnvironment.observation\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    136\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mobservation\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    137\u001B[0m   state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate()\n\u001B[1;32m--> 138\u001B[0m   observation \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    139\u001B[0m       name: renderer\u001B[38;5;241m.\u001B[39mrender(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mstate)\n\u001B[0;32m    140\u001B[0m       \u001B[38;5;28;01mfor\u001B[39;00m name, renderer \u001B[38;5;129;01min\u001B[39;00m six\u001B[38;5;241m.\u001B[39miteritems(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_renderers)\n\u001B[0;32m    141\u001B[0m   }\n\u001B[0;32m    142\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m observation\n",
      "File \u001B[1;32mC:\\Python310\\lib\\site-packages\\spriteworld\\environment.py:139\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    136\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mobservation\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    137\u001B[0m   state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate()\n\u001B[0;32m    138\u001B[0m   observation \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m--> 139\u001B[0m       name: renderer\u001B[38;5;241m.\u001B[39mrender(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mstate)\n\u001B[0;32m    140\u001B[0m       \u001B[38;5;28;01mfor\u001B[39;00m name, renderer \u001B[38;5;129;01min\u001B[39;00m six\u001B[38;5;241m.\u001B[39miteritems(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_renderers)\n\u001B[0;32m    141\u001B[0m   }\n\u001B[0;32m    142\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m observation\n",
      "File \u001B[1;32mC:\\Python310\\lib\\site-packages\\spriteworld\\renderers\\pil_renderer.py:89\u001B[0m, in \u001B[0;36mPILRenderer.render\u001B[1;34m(self, sprites, global_state)\u001B[0m\n\u001B[0;32m     87\u001B[0m im \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mnew(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRGB\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_canvas_size)\n\u001B[0;32m     88\u001B[0m ImageDraw\u001B[38;5;241m.\u001B[39mDraw(im)\u001B[38;5;241m.\u001B[39mpolygon([\u001B[38;5;28mtuple\u001B[39m(v) \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m vertices], fill\u001B[38;5;241m=\u001B[39mcolor)\n\u001B[1;32m---> 89\u001B[0m im \u001B[38;5;241m=\u001B[39m \u001B[43mim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_image_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresample\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mImage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mANTIALIAS\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     90\u001B[0m im \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mflipud(np\u001B[38;5;241m.\u001B[39marray(im))\n\u001B[0;32m     91\u001B[0m ims\u001B[38;5;241m.\u001B[39mappend(im)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\PIL\\Image.py:2082\u001B[0m, in \u001B[0;36mImage.resize\u001B[1;34m(self, size, resample, box, reducing_gap)\u001B[0m\n\u001B[0;32m   2074\u001B[0m             \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mreduce(\u001B[38;5;28mself\u001B[39m, factor, box\u001B[38;5;241m=\u001B[39mreduce_box)\n\u001B[0;32m   2075\u001B[0m         box \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   2076\u001B[0m             (box[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m-\u001B[39m reduce_box[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m/\u001B[39m factor_x,\n\u001B[0;32m   2077\u001B[0m             (box[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m-\u001B[39m reduce_box[\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;241m/\u001B[39m factor_y,\n\u001B[0;32m   2078\u001B[0m             (box[\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m-\u001B[39m reduce_box[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m/\u001B[39m factor_x,\n\u001B[0;32m   2079\u001B[0m             (box[\u001B[38;5;241m3\u001B[39m] \u001B[38;5;241m-\u001B[39m reduce_box[\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;241m/\u001B[39m factor_y,\n\u001B[0;32m   2080\u001B[0m         )\n\u001B[1;32m-> 2082\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_new(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresize\u001B[49m\u001B[43m(\u001B[49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbox\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Step 3: Make OOD no_overlap dataset\n",
    "\n",
    "n_samples = 5000\n",
    "n_slots = 2\n",
    "default_cfg = configs.SpriteWorldConfig()\n",
    "sample_mode = \"off_diagonal\"\n",
    "no_overlap = False\n",
    "delta = 0.125\n",
    "\n",
    "no_overlap_off_diagonal_dataset = data.SpriteWorldDataset(\n",
    "    n_samples,\n",
    "    n_slots,\n",
    "    default_cfg,\n",
    "    sample_mode=sample_mode,\n",
    "    no_overlap=no_overlap,\n",
    "    delta=delta,\n",
    "    transform=transforms.Compose(\n",
    "    [transforms.ToPILImage(), transforms.ToTensor()]),\n",
    "    z=no_overlap_z\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec8edaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating images (sampling: off_diagonal): 100%|███████████████████████████████| 10000/10000 [01:32<00:00, 107.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 2 - alternative:\n",
    "# Generate off_diagonal dataset and reject the pairs with close x-coordinates\n",
    "\n",
    "n_samples = 10000\n",
    "n_slots = 2\n",
    "default_cfg = configs.SpriteWorldConfig()\n",
    "sample_mode = \"off_diagonal\"\n",
    "no_overlap = False\n",
    "delta = 0.125\n",
    "\n",
    "off_diagonal_dataset = data.SpriteWorldDataset(\n",
    "    n_samples,\n",
    "    n_slots,\n",
    "    default_cfg,\n",
    "    sample_mode=sample_mode,\n",
    "    no_overlap=no_overlap,\n",
    "    delta=delta,\n",
    "    transform=transforms.Compose(\n",
    "    [transforms.ToPILImage(), transforms.ToTensor()])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd413562",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering objects:  75%|█████████████████████████████████████████▍             | 7524/10000 [00:00<00:00, 20246.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 2.1 filtering\n",
    "no_overlap_z = filter_objects(off_diagonal_dataset.z, max_objects=5000, threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc72d693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating images (sampling: off_diagonal): 100%|█████████████████████████████████| 5000/5000 [00:38<00:00, 128.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - alternative, filter the latents and create new data\n",
    "\n",
    "n_samples = 5000\n",
    "n_slots = 2\n",
    "default_cfg = configs.SpriteWorldConfig()\n",
    "sample_mode = \"off_diagonal\"\n",
    "no_overlap = False\n",
    "delta = 0.125\n",
    "\n",
    "no_overlap_off_diagonal_dataset = data.SpriteWorldDataset(\n",
    "    n_samples,\n",
    "    n_slots,\n",
    "    default_cfg,\n",
    "    sample_mode=sample_mode,\n",
    "    no_overlap=no_overlap,\n",
    "    delta=delta,\n",
    "    transform=transforms.Compose(\n",
    "    [transforms.ToPILImage(), transforms.ToTensor()]),\n",
    "    z=no_overlap_z\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b2177254",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_samples = len(no_overlap_off_diagonal_dataset)\n",
    "\n",
    "# Convert images to numpy arrays and add them to the images list\n",
    "images = []\n",
    "for i in range(num_samples):\n",
    "    img = no_overlap_off_diagonal_dataset[i][0][-1].permute(1, 2, 0).numpy()\n",
    "    \n",
    "    # Scaling the image data to [0, 255] and convert to uint8\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    \n",
    "    images.append(img)\n",
    "\n",
    "# Save images as a GIF\n",
    "imageio.mimsave('output.gif', images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eea0db98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating images (sampling: off_diagonal): 100%|█████████████████████████████████| 5000/5000 [00:49<00:00, 100.02it/s]\n"
     ]
    }
   ],
   "source": [
    "test = data.SpriteWorldDataset(\n",
    "    len(z_sampled),\n",
    "    n_slots,\n",
    "    default_cfg,\n",
    "    sample_mode=\"off_diagonal\",\n",
    "    no_overlap=True,\n",
    "    delta=delta,\n",
    "    transform=transforms.Compose(\n",
    "    [transforms.ToPILImage(), transforms.ToTensor()]),\n",
    "    z=z_sampled\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0d48151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b206a3249ba4e16b8080e2860635f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=4999), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_data(index):\n",
    "    plt.imshow(test[index][0][-1].permute(1, 2, 0))\n",
    "    plt.show()\n",
    "\n",
    "num_samples = len(test)\n",
    "\n",
    "# slider\n",
    "widgets.interact(display_data, index=widgets.IntSlider(min=0, max=num_samples-1, step=1, value=0));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "076aeca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(z_sampled)\n",
    "\n",
    "# Convert images to numpy arrays and add them to the images list\n",
    "images = []\n",
    "for i in range(num_samples):\n",
    "    img = test[i][0][-1].permute(1, 2, 0).numpy()\n",
    "    \n",
    "    # Scaling the image data to [0, 255] and convert to uint8\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    \n",
    "    images.append(img)\n",
    "\n",
    "# Save images as a GIF\n",
    "imageio.mimsave('output.gif', images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fe90ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [00:00, 6555.41it/s]\n"
     ]
    }
   ],
   "source": [
    "dump_generated_dataset(diagonal_dataset, \"D:/mnt/qb/work/bethge/apanfilov27/object_centric_consistency_project/dsprites/test/diagonal/4_objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5bd6e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:/mnt/qb/work/bethge/apanfilov27/object_centric_consistency_project/dsprites/train/diagonal/4_objects/latents/latents.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "24d89418",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents_4 = torch.load(\"D:/mnt/qb/work/bethge/apanfilov27/object_centric_consistency_project/dsprites/test/off_diagonal/4_objects/latents/latents.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8557b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(latents_4[:1666, ...], \"D:/mnt/qb/work/bethge/apanfilov27/object_centric_consistency_project/dsprites/test/off_diagonal/mixed/latents/latents_4.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f0795a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29ecfd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_delta_diagonal_cube(\n",
    "    n_samples: int, n_slots: int, n_latents: int, delta: float, oversampling: int = 100\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Sample near the diagonal in latent space i.e. all distances from the diagonal are less than delta.\n",
    "\n",
    "    Algorithm:\n",
    "        1. Draw points on the diagonal of [0, 1)^(n_slots, n_latents) cube.\n",
    "        2. For every latent draw uniformly noise from n_slots-dimensional ball. For drawing uniformly inside the ball we\n",
    "            use the following theorem (http://compneuro.uwaterloo.ca/files/publications/voelker.2017.pdf):\n",
    "            if point uniformly sampled from the (n+1)-sphere, then n-first coordinates are uniformly sampled from the n-ball.\n",
    "        3. Project sampled inside-ball points to the hyperplane perpendicular to the diagonal and normalize them\n",
    "            (this gives us points on (n_slots-2)-sphere embedded in n_slots-space).\n",
    "        4. Get final points by adding the diagonal point to the projected points.\n",
    "        5. Keep only points inside the [0, 1)^(n_slots, n_latents) cube.\n",
    "    \"\"\"\n",
    "    _n = oversampling * n_samples\n",
    "    z_out = torch.Tensor(0, n_slots, n_latents)\n",
    "    while z_out.shape[0] < n_samples:\n",
    "        # sample randomly on diagonal\n",
    "        z_sampled = torch.repeat_interleave(\n",
    "            torch.rand(_n, n_latents), n_slots, dim=0\n",
    "        ).reshape(_n, n_slots, n_latents)\n",
    "\n",
    "        # sample noise from n_slots-ball\n",
    "        noise = torch.randn(_n, n_slots + 2, n_latents)\n",
    "        noise = noise / torch.norm(noise, dim=1, keepdim=True)  # points on n-sphere\n",
    "        noise = noise[:, :n_slots, :]  # remove two last points\n",
    "\n",
    "        # project to hyperplane perpendicular to diagonal\n",
    "        ort_vec = noise - z_sampled * (noise * z_sampled).sum(axis=1, keepdim=True) / (\n",
    "            z_sampled * z_sampled\n",
    "        ).sum(axis=1, keepdim=True)\n",
    "        ort_vec /= torch.norm(ort_vec, p=2, dim=1, keepdim=True)\n",
    "\n",
    "        # final step\n",
    "        # why n - 1 here? because we sample\n",
    "        # \"radius\" not in the original space, but in the embedded\n",
    "        final = z_sampled + (\n",
    "            ort_vec\n",
    "            * torch.pow(torch.rand([_n, 1, n_latents]), 1 / (n_slots - 1))\n",
    "            * delta\n",
    "        )\n",
    "\n",
    "        # only keep samples inside [0, 1]^{k×l}\n",
    "        mask = ((final - 0.5).abs() <= 0.5).flatten(1).all(1)\n",
    "        idx = mask.nonzero().squeeze(1)\n",
    "\n",
    "        z_out = torch.cat([z_out, final[idx]])\n",
    "    z_out = z_out[:n_samples]\n",
    "    return z_out[:n_samples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b85a164",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'z' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 14\u001B[0m\n\u001B[0;32m     12\u001B[0m z_diag_scalar_component \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(z_ID\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m1\u001B[39m), diag_unit)\n\u001B[0;32m     13\u001B[0m z_diag_component \u001B[38;5;241m=\u001B[39m z_diag_scalar_component[:, \u001B[38;5;28;01mNone\u001B[39;00m, :] \u001B[38;5;241m*\u001B[39m diag_unit[\u001B[38;5;28;01mNone\u001B[39;00m, :, \u001B[38;5;28;01mNone\u001B[39;00m]\n\u001B[1;32m---> 14\u001B[0m z_orth_component \u001B[38;5;241m=\u001B[39m \u001B[43mz\u001B[49m \u001B[38;5;241m-\u001B[39m z_diag_component\n\u001B[0;32m     15\u001B[0m z_orth_component_norm \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39mnorm(z_orth_component, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     17\u001B[0m mask_ID \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mall(z_orth_component_norm \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m delta, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'z' is not defined"
     ]
    }
   ],
   "source": [
    "n = 10000\n",
    "n_slots = 2\n",
    "n_latents = 5\n",
    "delta = 0.5  # in [0 .. sqrt(n_slots)/2]\n",
    "\n",
    "# check that ID samples don't contain any OOD samples\n",
    "z_ID = sample_delta_diagonal_cube(n, n_slots, n_latents, delta).numpy()\n",
    "\n",
    "diag_unit = np.ones(n_slots) / np.sqrt(n_slots)\n",
    "# calculate the projection onto the diagonal (and from there the distance) along the\n",
    "# `slots`-dimension since one diagonal contains the i-th latent of each slot\n",
    "z_diag_scalar_component = np.dot(z_ID.transpose(0, 2, 1), diag_unit)\n",
    "z_diag_component = z_diag_scalar_component[:, None, :] * diag_unit[None, :, None]\n",
    "z_orth_component = z - z_diag_component\n",
    "z_orth_component_norm = np.linalg.norm(z_orth_component, axis=1)\n",
    "\n",
    "mask_ID = np.all(z_orth_component_norm <= delta, axis=1)\n",
    "mask_OOD_any = np.any(z_orth_component_norm > delta, axis=1)\n",
    "# mask_OOD_all = np.all(z_orth_component_norm > delta, axis=1)\n",
    "\n",
    "n_ID = mask_ID.sum()\n",
    "n_OOD_any = mask_OOD_any.sum()\n",
    "# n_OOD_all = mask_OOD_all.sum()\n",
    "\n",
    "print(n_ID, n_OOD_any, n_ID + n_OOD_any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e5a3f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

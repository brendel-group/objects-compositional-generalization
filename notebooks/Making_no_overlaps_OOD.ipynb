{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06c0d564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2232f097510>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.datasets import data, configs\n",
    "from src.datasets.utils import PreGeneratedDataset\n",
    "\n",
    "from torchvision import transforms as transforms\n",
    "\n",
    "seed = 43\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9554c463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering code, to remove overlapping objects OOD\n",
    "def filter_objects(latents, max_objects=5000, threshold=0.2, sort=False):\n",
    "    \"\"\"\n",
    "    Filter objects based on their Euclidean distance.\n",
    "    Args:\n",
    "        latents: Tensor of shape (batch_size, n_slots, n_latents)\n",
    "        max_objects: Number of objects to keep at most\n",
    "        threshold: Distance threshold\n",
    "        sort: Whether to sort the objects by distance\n",
    "    \"\"\"\n",
    "    N, slots, _ = latents.size()\n",
    "    mask = torch.zeros(N, dtype=bool)\n",
    "\n",
    "    # Compute Euclidean distance for each pair of slots in each item\n",
    "    for n in range(N):\n",
    "        slots_distances = torch.cdist(latents[n, :, :2], latents[n, :, :2], p=2)\n",
    "        slots_distances.fill_diagonal_(float(\"inf\"))  # Ignore distance to self\n",
    "\n",
    "        # Consider an object as \"close\" if its minimal distance to any other object is below the threshold\n",
    "        min_distance = slots_distances.min().item()\n",
    "        if min_distance >= threshold:\n",
    "            mask[n] = True\n",
    "\n",
    "    # If all objects are \"close\", print a message and return\n",
    "    if not torch.any(mask):\n",
    "        print(\"No objects were found that meet the distance threshold.\")\n",
    "        return None, []\n",
    "\n",
    "    # Apply the mask to the latents\n",
    "    filtered_objects = latents[mask]\n",
    "    filtered_indices = torch.arange(N)[mask]\n",
    "\n",
    "    # If the number of filtered objects exceeds the maximum, truncate them\n",
    "    if filtered_objects.size(0) > max_objects:\n",
    "        filtered_objects = filtered_objects[:max_objects]\n",
    "        filtered_indices = filtered_indices[:max_objects]\n",
    "\n",
    "    if sort:\n",
    "        # Sort the filtered objects by minimum distance to any other object\n",
    "        min_distances = torch.zeros(mask.sum().item())\n",
    "        for i, n in enumerate(torch.where(mask)[0]):\n",
    "            slots_distances = torch.cdist(latents[n], latents[n], p=2)\n",
    "            slots_distances.fill_diagonal_(float(\"inf\"))\n",
    "            min_distances[i] = slots_distances.min().item()\n",
    "\n",
    "        indices = torch.argsort(min_distances)\n",
    "        filtered_objects = filtered_objects[indices]\n",
    "        filtered_indices = filtered_indices[indices]\n",
    "\n",
    "    return filtered_objects, filtered_indices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aba3c949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating images (sampling: off_diagonal): 100%|███████████████████████████████| 10000/10000 [01:25<00:00, 117.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create a OOD dataset\n",
    "n_samples = 10000\n",
    "n_slots = 2\n",
    "default_cfg = configs.SpriteWorldConfig()\n",
    "sample_mode = \"off_diagonal\"\n",
    "no_overlap = True\n",
    "delta = 0.125\n",
    "\n",
    "off_diagonal_dataset = data.SpriteWorldDataset(\n",
    "    n_samples,\n",
    "    n_slots,\n",
    "    default_cfg,\n",
    "    sample_mode=sample_mode,\n",
    "    no_overlap=no_overlap,\n",
    "    delta=delta,\n",
    "    transform=transforms.Compose([transforms.ToPILImage(), transforms.ToTensor()]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "938e1eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the generated dataset\n",
    "def display_data(index, dataset):\n",
    "    plt.imshow(dataset[index][0][-1].permute(1, 2, 0))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "dispaly_off_diagonal = lambda index: display_data(index, dataset=off_diagonal_dataset)\n",
    "\n",
    "num_samples = len(off_diagonal_dataset)\n",
    "\n",
    "# slider\n",
    "widgets.interact(\n",
    "    dispaly_off_diagonal,\n",
    "    index=widgets.IntSlider(min=0, max=num_samples - 1, step=1, value=0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2da8741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Filter the dataset\n",
    "n_objects = 5000\n",
    "_, indicies = filter_objects(\n",
    "    off_diagonal_dataset.z, max_objects=n_objects, threshold=0.2\n",
    ")\n",
    "\n",
    "# save the filtered dataset\n",
    "path = \"mnt/qb/work/bethge/apanfilov27/object_centric_consistency_project/dsprites/test/new_ood/2_objects/\"\n",
    "torch.save(off_diagonal_dataset.x[indicies], os.join(path, \"images\", \"images.pt\"))\n",
    "torch.save(\n",
    "    torch.cat(\n",
    "        [\n",
    "            off_diagonal_dataset.z[indicies, :, :4],\n",
    "            off_diagonal_dataset.z[indicies, :, 5:-2],\n",
    "        ],\n",
    "        dim=-1,\n",
    "    ),\n",
    "    os.join(path, \"latents\", \"latents.pt\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c0d07dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the generated dataset\n",
    "\n",
    "no_overlaps_ood = PreGeneratedDataset(\n",
    "    \"D:/mnt/qb/work/bethge/apanfilov27/object_centric_consistency_project/dsprites/test/new_ood/2_objects\"\n",
    ")\n",
    "\n",
    "dispaly_no_overlaps_ood = lambda index: display_data(index, dataset=no_overlaps_ood)\n",
    "\n",
    "# slider\n",
    "widgets.interact(\n",
    "    dispaly_no_overlaps_ood,\n",
    "    index=widgets.IntSlider(min=0, max=n_objects - 1, step=1, value=0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fd22c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the OOD dataset for 2-4 objects\n",
    "n_samples = 10000\n",
    "default_cfg = configs.SpriteWorldConfig()\n",
    "sample_mode = \"off_diagonal\"\n",
    "no_overlap = False\n",
    "delta = 0.125\n",
    "\n",
    "for n_slots in [2, 3, 4]:\n",
    "    off_diagonal_dataset = data.SpriteWorldDataset(\n",
    "        n_samples,\n",
    "        n_slots,\n",
    "        default_cfg,\n",
    "        sample_mode=sample_mode,\n",
    "        no_overlap=no_overlap,\n",
    "        delta=delta,\n",
    "        transform=transforms.Compose([transforms.ToPILImage(), transforms.ToTensor()]),\n",
    "    )\n",
    "    n_objects = 1666\n",
    "    _, indicies = filter_objects(\n",
    "        off_diagonal_dataset.z, max_objects=n_objects, threshold=0.2\n",
    "    )\n",
    "    path = \"mnt/qb/work/bethge/apanfilov27/object_centric_consistency_project/dsprites/test/new_ood/mixed\"\n",
    "\n",
    "    torch.save(\n",
    "        off_diagonal_dataset.x[indicies],\n",
    "        os.join(path, \"images\", f\"images_{n_slots}.pt\"),\n",
    "    )\n",
    "    torch.save(\n",
    "        torch.cat(\n",
    "            [\n",
    "                off_diagonal_dataset.z[indicies, :, :4],\n",
    "                off_diagonal_dataset.z[indicies, :, 5:-2],\n",
    "            ],\n",
    "            dim=-1,\n",
    "        ),\n",
    "        os.join(path, \"latents\", f\"latents_{n_slots}.pt\"),\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
